{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6BlgWwoJdrt4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# device config\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvbN0odQwJNo",
        "outputId": "9a9d7e68-fcce-4a01-af39-4a6dfb6c4e10"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "num_epochs = 20\n",
        "batch_size = 4\n",
        "learning_rate = 0.001\n"
      ],
      "metadata": {
        "id": "j0kLc_QawSPD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset has PILImage images of range [0,1]\n",
        "# we transform them to tensor of normalized range [-1,1]\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))])\n"
      ],
      "metadata": {
        "id": "PGv6cYMNwZsD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data',train=False, download=True, transform = transform)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Mai6wQuwze_",
        "outputId": "9290d860-4906-4106-bd87-1489432b86cf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ('plane','car','bird', 'cat','deer','dog','frog', 'horse','ship', 'truck')\n",
        "classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gr3sOn3UxpfX",
        "outputId": "d774d095-2204-4a9b-8545-c03293d9f917"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('plane',\n",
              " 'car',\n",
              " 'bird',\n",
              " 'cat',\n",
              " 'deer',\n",
              " 'dog',\n",
              " 'frog',\n",
              " 'horse',\n",
              " 'ship',\n",
              " 'truck')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model architecture\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ConvNet,self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3,6,5)\n",
        "    self.pool = nn.MaxPool2d(2,2)\n",
        "    self.conv2 = nn.Conv2d(6,16,5)\n",
        "    self.fc1 = nn.Linear(16*5*5,120)\n",
        "    self.fc2 = nn.Linear(120,84)\n",
        "    self.fc3 = nn.Linear(84,10)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = x.view(-1,16*5*5)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n"
      ],
      "metadata": {
        "id": "s_GxGg4Cx4TC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ConvNet().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr= learning_rate)\n",
        "criterion.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXOyMBLFyIf8",
        "outputId": "7f89d5b0-62c3-4905-a3b3-a9bf88e6f346"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CrossEntropyLoss()"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_total_steps = len(train_dataloader)\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (images,labels) in enumerate(train_dataloader):\n",
        "    # origin shape: [4,3,32,32] = 4,3,1024\n",
        "    # input layer: 3 input channels, 6 output channels, 5 kernel size\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # forward pass\n",
        "\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs,labels)\n",
        "\n",
        "\n",
        "    # backward pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if(i+1)% 2000==0:\n",
        "      print(f'Epoch [{epoch+1}/{num_epochs}] Step [{i+1}/{n_total_steps}], loss: {loss.item():.4f}')\n",
        "\n",
        "print('training finished')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OWJNuZgOyYNw",
        "outputId": "d4f68372-02c5-4aa9-c43b-9da4a4423bc7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20] Step [2000/12500], loss: 2.3099\n",
            "Epoch [1/20] Step [4000/12500], loss: 2.3283\n",
            "Epoch [1/20] Step [6000/12500], loss: 2.2645\n",
            "Epoch [1/20] Step [8000/12500], loss: 2.2905\n",
            "Epoch [1/20] Step [10000/12500], loss: 2.1830\n",
            "Epoch [1/20] Step [12000/12500], loss: 2.3782\n",
            "Epoch [2/20] Step [2000/12500], loss: 1.9073\n",
            "Epoch [2/20] Step [4000/12500], loss: 1.3551\n",
            "Epoch [2/20] Step [6000/12500], loss: 1.3033\n",
            "Epoch [2/20] Step [8000/12500], loss: 2.5156\n",
            "Epoch [2/20] Step [10000/12500], loss: 2.0690\n",
            "Epoch [2/20] Step [12000/12500], loss: 2.2087\n",
            "Epoch [3/20] Step [2000/12500], loss: 1.5490\n",
            "Epoch [3/20] Step [4000/12500], loss: 1.0035\n",
            "Epoch [3/20] Step [6000/12500], loss: 1.3698\n",
            "Epoch [3/20] Step [8000/12500], loss: 1.8513\n",
            "Epoch [3/20] Step [10000/12500], loss: 1.9001\n",
            "Epoch [3/20] Step [12000/12500], loss: 1.5299\n",
            "Epoch [4/20] Step [2000/12500], loss: 1.2568\n",
            "Epoch [4/20] Step [4000/12500], loss: 1.0385\n",
            "Epoch [4/20] Step [6000/12500], loss: 2.1628\n",
            "Epoch [4/20] Step [8000/12500], loss: 1.3900\n",
            "Epoch [4/20] Step [10000/12500], loss: 1.2621\n",
            "Epoch [4/20] Step [12000/12500], loss: 1.4929\n",
            "Epoch [5/20] Step [2000/12500], loss: 1.1078\n",
            "Epoch [5/20] Step [4000/12500], loss: 0.7552\n",
            "Epoch [5/20] Step [6000/12500], loss: 1.4881\n",
            "Epoch [5/20] Step [8000/12500], loss: 0.8978\n",
            "Epoch [5/20] Step [10000/12500], loss: 1.8105\n",
            "Epoch [5/20] Step [12000/12500], loss: 1.6802\n",
            "Epoch [6/20] Step [2000/12500], loss: 0.9812\n",
            "Epoch [6/20] Step [4000/12500], loss: 0.6428\n",
            "Epoch [6/20] Step [6000/12500], loss: 1.0958\n",
            "Epoch [6/20] Step [8000/12500], loss: 1.5896\n",
            "Epoch [6/20] Step [10000/12500], loss: 2.3449\n",
            "Epoch [6/20] Step [12000/12500], loss: 0.4647\n",
            "Epoch [7/20] Step [2000/12500], loss: 2.5301\n",
            "Epoch [7/20] Step [4000/12500], loss: 1.4270\n",
            "Epoch [7/20] Step [6000/12500], loss: 1.1538\n",
            "Epoch [7/20] Step [8000/12500], loss: 1.0597\n",
            "Epoch [7/20] Step [10000/12500], loss: 1.3643\n",
            "Epoch [7/20] Step [12000/12500], loss: 1.3734\n",
            "Epoch [8/20] Step [2000/12500], loss: 1.2066\n",
            "Epoch [8/20] Step [4000/12500], loss: 0.6024\n",
            "Epoch [8/20] Step [6000/12500], loss: 0.7386\n",
            "Epoch [8/20] Step [8000/12500], loss: 1.1726\n",
            "Epoch [8/20] Step [10000/12500], loss: 1.1596\n",
            "Epoch [8/20] Step [12000/12500], loss: 1.7027\n",
            "Epoch [9/20] Step [2000/12500], loss: 0.4563\n",
            "Epoch [9/20] Step [4000/12500], loss: 0.6654\n",
            "Epoch [9/20] Step [6000/12500], loss: 1.0347\n",
            "Epoch [9/20] Step [8000/12500], loss: 2.2819\n",
            "Epoch [9/20] Step [10000/12500], loss: 0.9888\n",
            "Epoch [9/20] Step [12000/12500], loss: 1.0208\n",
            "Epoch [10/20] Step [2000/12500], loss: 1.5412\n",
            "Epoch [10/20] Step [4000/12500], loss: 0.9043\n",
            "Epoch [10/20] Step [6000/12500], loss: 0.7824\n",
            "Epoch [10/20] Step [8000/12500], loss: 1.2663\n",
            "Epoch [10/20] Step [10000/12500], loss: 1.4390\n",
            "Epoch [10/20] Step [12000/12500], loss: 0.9428\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-4f7f3d3c99e5>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                             )\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    121\u001b[0m             )\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             sgd(\n\u001b[0m\u001b[1;32m    124\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36msgd\u001b[0;34m(params, d_p_list, momentum_buffer_list, has_sparse_grad, foreach, fused, grad_scale, found_inf, weight_decay, momentum, lr, dampening, nesterov, maximize)\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_sgd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m     func(\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0md_p_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36m_multi_tensor_sgd\u001b[0;34m(params, grads, momentum_buffer_list, grad_scale, found_inf, weight_decay, momentum, lr, dampening, nesterov, maximize, has_sparse_grad)\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0mdevice_momentum_buffer_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m     ), indices in grouped_tensors.values():\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mdevice_params\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0mdevice_grads\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_grads_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/typing.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0;32mpass\u001b[0m  \u001b[0;31m# All real errors (not unhashable args) are raised below.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  n_correct=0\n",
        "  n_samples=0\n",
        "  n_class_correct = [0 for i in range(10)]\n",
        "  n_class_samples = [0 for i in range(10)]\n",
        "  for images, labels in test_dataloader:\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images)\n",
        "\n",
        "    # max returns (value, index)\n",
        "    _, predicted = torch.max(outputs,1)\n",
        "    n_samples += labels.size(0)\n",
        "    n_correct += (predicted ==labels).sum().item()\n",
        "\n",
        "    for i in range(batch_size):\n",
        "      label = labels[i]\n",
        "      pred = predicted[i]\n",
        "      if(label == pred):\n",
        "        n_class_correct[label] += 1\n",
        "      n_class_samples[label] +=1\n",
        "\n",
        "  acc = 100.0 * n_correct/n_samples\n",
        "  print(f'Accuracy of the network : {acc:.4f}%')\n",
        "\n",
        "  for i in range(10):\n",
        "    acc= 100.0 * n_class_correct[i]/n_class_samples[i]\n",
        "    print(f'Accuracy of class{classes[i]} : {acc:.4f} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zknPPGuozqkM",
        "outputId": "93b4639d-924c-4706-da96-62dc7770024e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network : 56.4300%\n",
            "Accuracy of classplane : 71.3000 %\n",
            "Accuracy of classcar : 73.7000 %\n",
            "Accuracy of classbird : 55.3000 %\n",
            "Accuracy of classcat : 17.9000 %\n",
            "Accuracy of classdeer : 35.1000 %\n",
            "Accuracy of classdog : 52.6000 %\n",
            "Accuracy of classfrog : 74.2000 %\n",
            "Accuracy of classhorse : 72.1000 %\n",
            "Accuracy of classship : 64.2000 %\n",
            "Accuracy of classtruck : 47.9000 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "au_ulh8b_RNC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}